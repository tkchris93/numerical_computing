\lab{Unit Testing In Python}{Unit Testing In Python}

\objective{Convey the importance of unit testing in code, especially in the corporate world. Unit testing in python is easy, valulable, and powerful. Any project manager will appreciate a developer who is able to accurately test their code.}

In school, coding projects are usually done by a single student in isolation.  However, when you write code in the real world, you often need to think about how other developers would react to your code, particularly developers working alongside you.
When working on projects with hundreds of thousand lines of code, it is nigh on impossible to understand how the individual functions work together to form your product.

Thankfully, there is a simple and elegant solution to this problem which keeps you as the developer from having to be omniscient about the code you are writing: Unit Testing.
Unit testing only requires you to know what the inputs and outputs of a function are.
Beyond that, you can rely on the unit tests that have been written to know whether or not the function, and by extension the software, is working as expected.
Unit testing helps you understand requirements, keeps you aware of dependency changes, and gives you confidence about where to find bugs when your code breaks.

TODO: Describe exactly what Unit Testing is

Imagine for a few moments that you are hired as a developer for a company. On your first day, you are assigned the task of figuring out why your banner upload tool isn't allowing some particular user to upload a banner.
Very quickly you discover that the user simply doesn't have sufficient credentials to use the tool. At this point, you have two options: you can either change the individual user's credentials, or change the credential requirements for users wanting to use the upload tool.
You decide to go with the latter and change the requirments for the upload. Then you mark the task as complete, and your code is shipped for the user to see.
Very soon, however, the bug fix comes back to haunt you! Now that same person who tried to upload the banner in the beginning is having the same issue again.
In confusion, you go back to find that your coworker had changed the permissions back to fix an issue where anyone could upload a banner, including those who did not have any credentials at all.
So, now you're back to where you started.  It isn't strictly your coworker's fault that you are tasked with the same bug again, though, since there was nothing to indicate to him that he should not have simply put that code back in place.

Unit testing is the perfect thing to implement in order to keep this sort of thing from happening.
A well written unit test would have prevented you from editing the code to allow any user to add a banner; i.e., running the pre-written unit testes would have alerted you to the fact that your fix was inappropriate.

Test coverage is even sometimes used in the sales arena to describe the quality of a product!

\section*{PyTest}

Okay, so we've disscussed enough of the why. Now we will explore the "how" of testing code in python.
It is easiest and most efficient to think about testing individual functions rather than entire files or modules.
(As we will discuss later, even testing classes should happen on a function level.)
For example, we might test the following function

\begin{lstlisting}
>>> def addition(a,b):
...     return a+b
\end{lstlisting}
with this test function:
\begin{lstlisting}
>>> from solutions import addition
>>> def test_addition():
...     assert addition(1,3) == 4
...     assert addition(5,7) == 12
...     assert addition(6,14) == 20
\end{lstlisting}

\begin{info}
Just so you know:
\begin{lstlisting}
assert <truth statement>, 'message'
\end{lstlisting}
raises an AssertionError with error message \li{'message'} if \li{<truth statement>} is false.  Otherwise, it does nothing.
\end{info}


Now this is all well and good; we can write tests for a function by using the \li{assert} function with expected inputs and outputs.
However, there is a more practical and useful way to do this.  PyTest is a tool that allows you to aggregate your tests and give you more information about their results.
Try running the following from the terminal in your current directory:

\begin{lstlisting}
  $ py.test
\end{lstlisting}

Unless you've already written some tests, you probably got something like this:

\begin{lstlisting}
============================= test session starts =============================
platform win32 -- Python 2.7.10 -- py-1.4.27 -- pytest-2.7.1
rootdir: C:\Users\Tanner\ACME Labs for class, inifile:
collected 0 items

==============================  in 0.13 seconds ===============================
\end{lstlisting}


Even if you have already written some tests, pytest will not find them unless their filenames have the form test\_*.py or *\_test.py.  In addition, the test methods inside the files need to follow suit and be named \li{test_*()} or \li{*_test()}.  (If you need to change this for some reason, you can consult \href{http://pytest.org/latest/example/pythoncollection.html} {the documentation}.)


For example, consider the following directory: (note: the \li{tree} command in a terminal lists the contents of a directory recursively.)
\begin{lstlisting}[language=bash]
$ tree
|-- api_tests
|   |-- test_accounts.py
|   |-- test_auth.py
|   |-- test_base.py
|   |-- test_common.py
|-- platform_tests
      |-- test_bulk.py
      |-- test_calendar.py
      |-- test_google.py
\end{lstlisting}

If you run \li{py.test} here, the following output is produced:

\begin{lstlisting}
========================= test session starts ==========================
platform darwin -- Python 2.7.10 -- py-1.4.27 -- pytest-2.7.1
rootdir: /Users/lnelson/Desktop/ACME_WORK/python_tests, inifile:
collected 29 items

api_tests/test_accounts.py ....
api_tests/test_auth.py .....
api_tests/test_base.py ....
api_tests/test_common.py ....
platform_tests/test_bulk.py ....
platform_tests/test_calendar.py ..
platform_tests/test_google.py ......
======================= 29 passed in 0.07 seconds =======================
\end{lstlisting}
\begin{info}
Each dot represents a test passing. They show up in order, so, for example, if instead of the third dot there is an "F" (meaning test failed), you would know the third test in the respective file failed.
\end{info}

Understanding which parts of your code are and are not being tested is a very useful way to get an idea of how well a project is being tested.
An easy way to do this is to install a tool called \li{pytest-cov}. For some reason, pytest comes bundled with Anaconda while pytest-cov does not.  However, you should be able to install it from the terminal by running the following:
\begin{lstlisting}
  $ pip install pytest-cov
\end{lstlisting}
Now adding the flag "--cov" to py.test will give you a breakdown of test coverage on your code.
\begin{lstlisting}
  $ py.test --cov
======================= test session starts ========================
platform darwin -- Python 2.7.10 -- py-1.4.27 -- pytest-2.7.1
rootdir: /Users/lnelson/Desktop/ACME_WORK/python_tests, inifile:
plugins: cov
collected 29 items

api_tests/test_accounts.py ....
api_tests/test_auth.py .....
api_tests/test_base.py ....
api_tests/test_common.py ....
platform_tests/test_bulk.py ....
platform_tests/test_calendar.py ..
platform_tests/test_google.py ......
--------- coverage: platform darwin, python 2.7.10-final-0 ---------
Name                              Stmts   Miss  Cover
-----------------------------------------------------
api_tests/test_accounts.py            8      0   100%
api_tests/test_auth.py               10      0   100%
api_tests/test_base.py                8      0   100%
api_tests/test_common.py              8      0   100%
platform_tests/test_bulk.py           8      0   100%
platform_tests/test_calendar.py       4      0   100%
platform_tests/test_google.py        12      0   100%
-----------------------------------------------------
TOTAL                                58      0   100%

==================== 29 passed in 0.07 seconds =====================
\end{lstlisting}

The above of course give 100\% coverage because the only files gathered were test files, and pytest runs those files in their entirety.  TODO: give examples that are more substantial and relevant.

\begin{problem}
Install pytest-cov with pip.
Run "py.test --cov" in the directory which has the two files "solutions.py" and "test\_solutions.py" to see how well the tests are covering your code.

Now write some of your own tests for the addition function and the Fibonacci function. Be sure to give each function its own test. (This is more of a convention than mandate,
but it's good practice and will allow you to track down bugs quickly in the future.) Be sure that your tests cover every statement of your code in those two functions.
(The number of statments missed should go from 100 to 94 TODO double check this)
\end{problem}

\section*{pytest as a module}

When developing software, we often want our code to raise an exception when certain input is given, instead of proceeding.  Furthermore, we want the exception to give us relevant info about what went wrong and why it was raised.
For example, if a user feeds a bad value to a calculator (like dividing by 0), we would like if if the calculator were very explicit as to why it wasn't able to process our input.
Just as you should test your code to make sure valid cases give the correct output, like you did in the Problem 1, you should also test cases that generate an exception.  Standard assert functions, however, simply will not do, because they can't catch an exception.

Instead, we can use the \li{raises} method from the \li{pytest} module, which acts like an assert statement for raising and catching exceptions.
%Of course, a function may have several different types of exceptions to throw depending on the input, so to guarantee good coverage, you'll want to have multiple \li{raises} statements.
Consider the following example:

\begin{lstlisting}
>>> def divide(a,b):
...     if b==0:
...         raise ValueError("You can't give a zero for b, that breaks this function")
...     else:
...         return float(a)/float(b)
\end{lstlisting}
The above function could be tested by this test function:
\begin{lstlisting}
>>> import pytest
>>> def test_divide():
...     assert divide(1,2) == .5
...     assert divide(5,4) == 1.25
...     pytest.raises(ValueError, divide, a=4, b=0)

\end{lstlisting}

The above code tests whether or not a \li{ValueError} is raised when \li{divide} is called with the arguments \li{a=4} and \li{b=0}.  However, it does not allow us to test whether the message that came with the error is what we want it to be.  To do that, we can combine \li{raises} with the \li{with} statement, like so:

\begin{lstlisting}
...     with pytest.raises(Exception) as excinfo:
...         divide(4,0)
...     assert excinfo.typename == 'ValueError'
...     assert excinfo.value.args[0] == "You can't give a zero for b, that breaks this function"
\end{lstlisting}

In this example, \li{excinfo} is an object of type \li{py.code.ExceptionInfo()} which contains info about the exception that was raised.  Once we have raised the expection within the \li{with} block, we can assert whatever we want about the different attributes of \li{execinfo} to test whether we raised the right exception.

\begin{problem}
Write tests for the \li{operator} function.  Be sure to handle every statment and check against every exception.
For exceptions, be sure to check both the typename and the message, that way you can say with certainty that the test is adequately testing your code.
(The number of statments missed should go from 94 to 79 TODO: double-check this)
\end{problem}

Pytest also offers an option to make "pytest fixtures". These are wildly useful for mocking data or preventing constant code duplication.
Mocking data is useful when you don't want certain test to be dependent on the working of completely seperate code.
For example if we had a feature which was dependent upon a user service working correctly, rather than having my tests make a call to the user service I may write a fixture which simply gives exsisting mock data that I expect for my feature.
As far as preventing code duplication a fixture may also be utilized to create a class object which we can then call within our function.

\begin{lstlisting}
class ComplexNumber(object):
... def __init__(self, real=0, imag=0):
...     self.real = real
...     self.imag = imag
... def conjugate(self):
...     conjugate = ComplexNumber(real=self.real, imag=-self.imag)
...     return conjugate
... def norm(self):
...     magnitude = math.sqrt(self.real**2 + self.imag**2)
...     return magnitude
... def __add__(self, other):
...     real = self.real + other.real
...     imag = self.imag + other.imag
...     return ComplexNumber(real=real, imag=imag)
... def __sub__(self, other):
...     real = self.real - other.real
...     imag = self.imag - other.imag
...     return ComplexNumber(real=real, imag=imag)
... def __mul__(self, other):
...     real = self.real*other.real - self.imag*other.imag
...     imag = self.imag*other.real + other.imag*self.real
...     return ComplexNumber(real=real, imag=imag)
... def __div__(self, other):
...     if other.real==0 and other.imag==0:
...         raise ValueError("Cannot divide by zero")
...     bottom = (other.conjugate()*other*1.).real
...     top = self*other.conjugate()
...     return ComplexNumber(real=(top.real/bottom), imag=(top.imag/bottom))
... def __eq__(self, other):
...     return self.imag == other.imag and self.real == other.real
... def __str__(self):
...     return str(self.real)+('+' if self.imag>=0 else '')+str(self.imag)+'i'
\end{lstlisting}
Given the previous class, you could reduce code setup for your tests by using a test fixture like so:
\begin{lstlisting}
>>> from solutions import ComplexNumber
>>> import pytest
>>> @pytest.fixture
... def set_up_complex_nums():
...     number_1 = ComplexNumber(1, 2)
...     number_2 = ComplexNumber(5, 5)
...     number_3 = ComplexNumber(2, 9)
...     return number_1, number_2, number_3
>>> def test_complex_addition(set_up_complex_nums):
...     number_1, number_2, number_3 = set_up_complex_nums
...     assert number_1 + number_2 == ComplexNumber(6, 7)
...     assert number_1 + number_3 == ComplexNumber(3, 11)
...     assert number_2 + number_3 == ComplexNumber(7, 14)
...     assert number_3 + number_3 == ComplexNumber(4, 18)
>>> def test_complex_multiplication(set_up_complex_nums):
...     number_1, number_2, number_3 = set_up_complex_nums
...     assert number_1 * number_2 == ComplexNumber(-5, 15)
...     assert number_1 * number_3 == ComplexNumber(-17, 11)
...     assert number_2 * number_3 == ComplexNumber(-40, 50)
...     assert number_3 * number_3 == ComplexNumber(-80, 18)
\end{lstlisting}

\begin{problem}
Finish writing unit test for the complex numbers class. Be sure to utilize fixtures in order to reduce on the length of your code.
Also, remember, it would be useful (and good practice) to write a different test function for each method in the ComplexNumberClass.
(The number of statments missed should go from \_\_ to \_\_ TODO: this)
\end{problem}

\begin{problem}
Write unit tests for the \li{LinkedListNode} and \li{LinkedList} classes provided in solutions.py. It is not necessary, but it will help you to get total line coverage if every function has its own test.
If you have trouble finding everything, consider commenting out sections of code in solutions.py and seeing if the number of statements missed goes down.
If it does, then you know that part of what you deleted is un-tested.
(At the end of this the number of missed statments should be 0.)
\end{problem}

\section*{Test Driven Development}

Kent Beck, the creator of \href{https://en.wikipedia.org/wiki/Extreme_programming}{extreme programming}, claims to have re-discovered  Test Driven Development (TDD). He said,
"The original description of TDD was in an ancient book about programming. It said you take the input tape, manually type in the output tape you expect, then program until the actual output tape matches the expected output."
TDD incentivizes simple design, elegant code, and gives quantifiable checkpoints in the development proccess.
The idea is simple enough:
\begin{tikzpicture}
\matrix [column sep=40mm, row sep=5mm] {
  & \node (id) [draw, shape=rectangle] {    Idea    }; & \\
  & \node (ts) [draw, shape=circle] {    Test    }; & \\
  & \node (im) [draw, shape=rectangle] {Implementation}; & \\
};
\draw[->, thick] (id) -- (ts);
\draw[->, thick] (ts) -- (im);
\end{tikzpicture}\\
The idea must be a bit more concrete then "I want to add a chat room to my website." The general idea of how the chat room will look in code (like a history module, a data base, and a sketch of required functions, etc.) is required.
Next that idea is transformed into tests because the inputs and outputs of required functionality are understood.
Following the example of the chat room, you could write a unit test that checks what a given API returns when a user has broadcasted some message.
The implementation is simply adding, changing and editing code until all the required tests pass.

\begin{problem}
Use TDD to create a module which takes the string representation of a polynomial (of one arbitary variable) and plots it. For example it should take in:
"$5x^4 + 4x^3 + 3x^2+ 2x + 1$" and plot it
Equivlently "$5y^4 + 4y^3 + 3y^2+ 2y + 1$" (you may throw an excpetion if two variables are given).
(If you wanna get really "Wolfram Alpha-y", allow "$5y4 + 4y3 + 3y2+ 2y + 1$ as valid input.)  TODO: clean this up, add a graph, more guidelines as to how to implement TDD
\end{problem}


